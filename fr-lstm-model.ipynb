{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-10T05:54:26.997416Z",
     "iopub.status.busy": "2025-02-10T05:54:26.997148Z",
     "iopub.status.idle": "2025-02-10T05:54:27.772328Z",
     "shell.execute_reply": "2025-02-10T05:54:27.771419Z",
     "shell.execute_reply.started": "2025-02-10T05:54:26.997389Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:54:27.773491Z",
     "iopub.status.busy": "2025-02-10T05:54:27.773111Z",
     "iopub.status.idle": "2025-02-10T05:54:31.112931Z",
     "shell.execute_reply": "2025-02-10T05:54:31.112207Z",
     "shell.execute_reply.started": "2025-02-10T05:54:27.773469Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "Current Device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Check if GPU is available\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "\n",
    "# Print current device\n",
    "print(\"Current Device:\", torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "\n",
    "# Show available GPU\n",
    "if torch.cuda.is_available():\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
    "    print(\"CUDA Version:\", torch.version.cuda)\n",
    "    print(\"PyTorch Version:\", torch.__version__)\n",
    "\n",
    "import torch\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:54:31.114214Z",
     "iopub.status.busy": "2025-02-10T05:54:31.113761Z",
     "iopub.status.idle": "2025-02-10T05:54:31.118452Z",
     "shell.execute_reply": "2025-02-10T05:54:31.117538Z",
     "shell.execute_reply.started": "2025-02-10T05:54:31.114177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# storage for hyperparameters used in the model\n",
    "\n",
    "file_path = \"data/kloiya.csv\"\n",
    "\n",
    "# Hyperparameters\n",
    "\n",
    "# for input \n",
    "sequence_length = 28 # a week per sequence\n",
    "input_size = 1 # flow rate is one feature \n",
    "\n",
    "#for model\n",
    "hidden_size = 64\n",
    "num_layers = 3\n",
    "output_size = 1 \n",
    "\n",
    "# for training\n",
    "batch_size = 128\n",
    "learning_rate = 0.0003\n",
    "num_epochs = 80\n",
    "\n",
    "# setting up for CUDA\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:54:31.120693Z",
     "iopub.status.busy": "2025-02-10T05:54:31.120378Z",
     "iopub.status.idle": "2025-02-10T05:54:31.136346Z",
     "shell.execute_reply": "2025-02-10T05:54:31.135361Z",
     "shell.execute_reply.started": "2025-02-10T05:54:31.120664Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM_fr_model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size \n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Defined LSTM layer using torch.nn\n",
    "        self.lstm = nn.LSTM(input_size,hidden_size,num_layers, batch_first=True) #this will create the LSTM with pytorch\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size,output_size) #it will map the last hidden into an output\n",
    "\n",
    "    # writing the forward pass\n",
    "    def forward(self,x):\n",
    "        batch_size= x.shape[0]\n",
    "\n",
    "        # initializes hidden and cell states with the correct shape\n",
    "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(x.device)\n",
    "\n",
    "        # Pass input through LSTM, discard hidden and cell states\n",
    "        lstm_out, (hn, cn) = self.lstm(x, (h0, c0))\n",
    "\n",
    "        # Extracting the last timestep's output \n",
    "        last_out = lstm_out[:,-1,:]\n",
    "\n",
    "        # Passing through the fully connected layer\n",
    "        output = self.fc(last_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:54:31.137935Z",
     "iopub.status.busy": "2025-02-10T05:54:31.137643Z",
     "iopub.status.idle": "2025-02-10T05:54:31.151865Z",
     "shell.execute_reply": "2025-02-10T05:54:31.151232Z",
     "shell.execute_reply.started": "2025-02-10T05:54:31.137907Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "class FlowRate(): #flow rate function that creates the sequences inside the batch. \n",
    "    def __init__(self, data, sequence_length):\n",
    "        self.sequence_length = sequence_length\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self): # this method returns the number of sequences that can be made with the data with a counting principle\n",
    "        return len(self.data) - self.sequence_length\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index : index + self.sequence_length] #get the sequence\n",
    "        y = self.data[index + self.sequence_length] # gets the target value to calculate loss\n",
    "        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32) # This returns tuple (sequence,target)\n",
    "\n",
    "\n",
    "def load_data(my_data,sequence_length,batch_size,shuffle = \"True\"): #due to missing values in the dataset, linear interpolation must be used\n",
    "    # read the data out of flow rate and linearly interpolate between missing dates\n",
    "    df = pd.read_csv(my_data, parse_dates=[\"Date\"], date_format=\"%Y/%m/%d\")\n",
    "    df.set_index(\"Date\",inplace=True)\n",
    "    \n",
    "    # Check for duplicate dates\n",
    "    if df.index.duplicated().any():\n",
    "        print(\"Removing duplicates...\")\n",
    "        df = df[~df.index.duplicated(keep=\"first\")]  # Keep first occurrence\n",
    "\n",
    "    # create the full range of data, with empty slots to interpolate\n",
    "    new_range = pd.date_range(start=df.index.min(), end=df.index.max(), freq=\"D\")\n",
    "    df = df.reindex(new_range)\n",
    "    df[\"Value\"] = df[\"Value\"].interpolate(method=\"linear\")    \n",
    "\n",
    "    # convert into a numpy array\n",
    "    num_data = df[\"Value\"].values\n",
    "\n",
    "    dataset = FlowRate(num_data,sequence_length)\n",
    "    dataloader = torch.utils.data.DataLoader(dataset,batch_size=batch_size,shuffle=False) # we dont want to shuffle sequential data\n",
    "    \n",
    "    return dataloader\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:54:31.152828Z",
     "iopub.status.busy": "2025-02-10T05:54:31.152603Z",
     "iopub.status.idle": "2025-02-10T05:54:33.259066Z",
     "shell.execute_reply": "2025-02-10T05:54:33.258324Z",
     "shell.execute_reply.started": "2025-02-10T05:54:31.152808Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before split: X shape: (595084, 28), y shape: (595084,)\n",
      "âœ… X_train shape: torch.Size([416558, 28]), y_train shape: torch.Size([416558])\n",
      "âœ… X_valid shape: torch.Size([89263, 28]), y_valid shape: torch.Size([89263])\n",
      "âœ… X_test shape: torch.Size([89263, 28]), y_test shape: torch.Size([89263])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"kloiya.csv\"\n",
    "dataset = load_data(file_path, sequence_length, batch_size)\n",
    "\n",
    "# Extract raw data from DataLoader\n",
    "raw_data = []\n",
    "for batch in dataset:\n",
    "    raw_data.extend(batch[0].cpu().numpy().flatten())  # Convert to NumPy\n",
    "\n",
    "dataset = np.array(raw_data)\n",
    "\n",
    "# Prepare sequences for LSTM\n",
    "X, y = [], []\n",
    "for i in range(len(dataset) - sequence_length):\n",
    "    X.append(dataset[i:i + sequence_length])\n",
    "    y.append(dataset[i + sequence_length])  \n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "print(f\"Before split: X shape: {X.shape}, y shape: {y.shape}\")\n",
    "# Split train (70%) and train+valid set (30%) (which will be further split)\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Then, split test+valid into validation (15%) and test (15%)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, shuffle=False)\n",
    "\n",
    "# normalize all data \n",
    "train_min, train_max = X_train.min(), X_train.max()\n",
    "X_train = (X_train - train_min) / (train_max - train_min)\n",
    "y_train = (y_train - train_min) / (train_max - train_min)\n",
    "\n",
    "valid_min, valid_max = X_valid.min(), X_valid.max()\n",
    "X_valid = (X_valid - valid_min) / (valid_max - valid_min)\n",
    "y_valid = (y_valid - valid_min) / (valid_max - valid_min)\n",
    "\n",
    "test_min, test_max = X_test.min(), X_test.max()\n",
    "X_test = (X_test - test_min) / (test_max - test_min)\n",
    "y_test = (y_test - test_min) / (test_max - test_min)\n",
    "\n",
    "# Convert to tensors \n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_valid = torch.tensor(X_valid, dtype=torch.float32)\n",
    "y_valid = torch.tensor(y_valid, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n",
    "#  Move to GPU for GPU training \n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
    "X_test, y_test = X_test.to(device), y_test.to(device)\n",
    "\n",
    "# Print Data Shapes\n",
    "print(f\"âœ… X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"âœ… X_valid shape: {X_valid.shape}, y_valid shape: {y_valid.shape}\")\n",
    "print(f\"âœ… X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T05:54:33.260046Z",
     "iopub.status.busy": "2025-02-10T05:54:33.259825Z",
     "iopub.status.idle": "2025-02-10T06:40:27.687724Z",
     "shell.execute_reply": "2025-02-10T06:40:27.686970Z",
     "shell.execute_reply.started": "2025-02-10T05:54:33.260016Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Epoch [1/80]\n",
      "âœ… Training Loss: 0.001176\n",
      "âœ… Validation Loss: 0.001749\n",
      "ðŸ“‰ RMSE: 0.0418 | MAE: 0.0237 | RÂ² Score: 0.6213\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [2/80]\n",
      "âœ… Training Loss: 0.000596\n",
      "âœ… Validation Loss: 0.001242\n",
      "ðŸ“‰ RMSE: 0.0352 | MAE: 0.0195 | RÂ² Score: 0.7311\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [3/80]\n",
      "âœ… Training Loss: 0.000444\n",
      "âœ… Validation Loss: 0.001381\n",
      "ðŸ“‰ RMSE: 0.0372 | MAE: 0.0225 | RÂ² Score: 0.7009\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [4/80]\n",
      "âœ… Training Loss: 0.000366\n",
      "âœ… Validation Loss: 0.000696\n",
      "ðŸ“‰ RMSE: 0.0264 | MAE: 0.0175 | RÂ² Score: 0.8493\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [5/80]\n",
      "âœ… Training Loss: 0.000285\n",
      "âœ… Validation Loss: 0.000586\n",
      "ðŸ“‰ RMSE: 0.0242 | MAE: 0.0156 | RÂ² Score: 0.8731\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [6/80]\n",
      "âœ… Training Loss: 0.000263\n",
      "âœ… Validation Loss: 0.000613\n",
      "ðŸ“‰ RMSE: 0.0247 | MAE: 0.0162 | RÂ² Score: 0.8674\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [7/80]\n",
      "âœ… Training Loss: 0.000249\n",
      "âœ… Validation Loss: 0.000648\n",
      "ðŸ“‰ RMSE: 0.0255 | MAE: 0.0163 | RÂ² Score: 0.8597\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [8/80]\n",
      "âœ… Training Loss: 0.000240\n",
      "âœ… Validation Loss: 0.000583\n",
      "ðŸ“‰ RMSE: 0.0242 | MAE: 0.0142 | RÂ² Score: 0.8737\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [9/80]\n",
      "âœ… Training Loss: 0.000235\n",
      "âœ… Validation Loss: 0.001008\n",
      "ðŸ“‰ RMSE: 0.0317 | MAE: 0.0157 | RÂ² Score: 0.7818\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [10/80]\n",
      "âœ… Training Loss: 0.000228\n",
      "âœ… Validation Loss: 0.000726\n",
      "ðŸ“‰ RMSE: 0.0269 | MAE: 0.0181 | RÂ² Score: 0.8429\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [11/80]\n",
      "âœ… Training Loss: 0.000223\n",
      "âœ… Validation Loss: 0.000558\n",
      "ðŸ“‰ RMSE: 0.0236 | MAE: 0.0152 | RÂ² Score: 0.8792\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [12/80]\n",
      "âœ… Training Loss: 0.000229\n",
      "âœ… Validation Loss: 0.000697\n",
      "ðŸ“‰ RMSE: 0.0264 | MAE: 0.0178 | RÂ² Score: 0.8490\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [13/80]\n",
      "âœ… Training Loss: 0.000226\n",
      "âœ… Validation Loss: 0.000787\n",
      "ðŸ“‰ RMSE: 0.0281 | MAE: 0.0184 | RÂ² Score: 0.8296\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [14/80]\n",
      "âœ… Training Loss: 0.000224\n",
      "âœ… Validation Loss: 0.000640\n",
      "ðŸ“‰ RMSE: 0.0253 | MAE: 0.0171 | RÂ² Score: 0.8614\n",
      "ðŸ›‘ No improvement. Early stopping counter: 3/10\n",
      "\n",
      "ðŸ“Š Epoch [15/80]\n",
      "âœ… Training Loss: 0.000223\n",
      "âœ… Validation Loss: 0.000820\n",
      "ðŸ“‰ RMSE: 0.0286 | MAE: 0.0179 | RÂ² Score: 0.8225\n",
      "ðŸ›‘ No improvement. Early stopping counter: 4/10\n",
      "\n",
      "ðŸ“Š Epoch [16/80]\n",
      "âœ… Training Loss: 0.000214\n",
      "âœ… Validation Loss: 0.000822\n",
      "ðŸ“‰ RMSE: 0.0287 | MAE: 0.0162 | RÂ² Score: 0.8220\n",
      "ðŸ›‘ No improvement. Early stopping counter: 5/10\n",
      "\n",
      "ðŸ“Š Epoch [17/80]\n",
      "âœ… Training Loss: 0.000223\n",
      "âœ… Validation Loss: 0.000494\n",
      "ðŸ“‰ RMSE: 0.0222 | MAE: 0.0134 | RÂ² Score: 0.8930\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [18/80]\n",
      "âœ… Training Loss: 0.000208\n",
      "âœ… Validation Loss: 0.000501\n",
      "ðŸ“‰ RMSE: 0.0224 | MAE: 0.0137 | RÂ² Score: 0.8916\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [19/80]\n",
      "âœ… Training Loss: 0.000206\n",
      "âœ… Validation Loss: 0.000550\n",
      "ðŸ“‰ RMSE: 0.0235 | MAE: 0.0129 | RÂ² Score: 0.8808\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [20/80]\n",
      "âœ… Training Loss: 0.000200\n",
      "âœ… Validation Loss: 0.000489\n",
      "ðŸ“‰ RMSE: 0.0221 | MAE: 0.0136 | RÂ² Score: 0.8940\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [21/80]\n",
      "âœ… Training Loss: 0.000196\n",
      "âœ… Validation Loss: 0.000422\n",
      "ðŸ“‰ RMSE: 0.0205 | MAE: 0.0134 | RÂ² Score: 0.9086\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [22/80]\n",
      "âœ… Training Loss: 0.000187\n",
      "âœ… Validation Loss: 0.000417\n",
      "ðŸ“‰ RMSE: 0.0204 | MAE: 0.0126 | RÂ² Score: 0.9098\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [23/80]\n",
      "âœ… Training Loss: 0.000185\n",
      "âœ… Validation Loss: 0.000375\n",
      "ðŸ“‰ RMSE: 0.0194 | MAE: 0.0117 | RÂ² Score: 0.9188\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [24/80]\n",
      "âœ… Training Loss: 0.000179\n",
      "âœ… Validation Loss: 0.000416\n",
      "ðŸ“‰ RMSE: 0.0204 | MAE: 0.0127 | RÂ² Score: 0.9099\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [25/80]\n",
      "âœ… Training Loss: 0.000173\n",
      "âœ… Validation Loss: 0.000409\n",
      "ðŸ“‰ RMSE: 0.0202 | MAE: 0.0123 | RÂ² Score: 0.9115\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [26/80]\n",
      "âœ… Training Loss: 0.000177\n",
      "âœ… Validation Loss: 0.000352\n",
      "ðŸ“‰ RMSE: 0.0188 | MAE: 0.0116 | RÂ² Score: 0.9238\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [27/80]\n",
      "âœ… Training Loss: 0.000169\n",
      "âœ… Validation Loss: 0.000340\n",
      "ðŸ“‰ RMSE: 0.0184 | MAE: 0.0116 | RÂ² Score: 0.9264\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [28/80]\n",
      "âœ… Training Loss: 0.000168\n",
      "âœ… Validation Loss: 0.000381\n",
      "ðŸ“‰ RMSE: 0.0195 | MAE: 0.0124 | RÂ² Score: 0.9175\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [29/80]\n",
      "âœ… Training Loss: 0.000170\n",
      "âœ… Validation Loss: 0.000370\n",
      "ðŸ“‰ RMSE: 0.0192 | MAE: 0.0123 | RÂ² Score: 0.9198\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [30/80]\n",
      "âœ… Training Loss: 0.000163\n",
      "âœ… Validation Loss: 0.000342\n",
      "ðŸ“‰ RMSE: 0.0185 | MAE: 0.0107 | RÂ² Score: 0.9259\n",
      "ðŸ›‘ No improvement. Early stopping counter: 3/10\n",
      "\n",
      "ðŸ“Š Epoch [31/80]\n",
      "âœ… Training Loss: 0.000161\n",
      "âœ… Validation Loss: 0.000322\n",
      "ðŸ“‰ RMSE: 0.0179 | MAE: 0.0098 | RÂ² Score: 0.9303\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [32/80]\n",
      "âœ… Training Loss: 0.000160\n",
      "âœ… Validation Loss: 0.000382\n",
      "ðŸ“‰ RMSE: 0.0195 | MAE: 0.0115 | RÂ² Score: 0.9174\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [33/80]\n",
      "âœ… Training Loss: 0.000158\n",
      "âœ… Validation Loss: 0.000321\n",
      "ðŸ“‰ RMSE: 0.0179 | MAE: 0.0103 | RÂ² Score: 0.9306\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [34/80]\n",
      "âœ… Training Loss: 0.000154\n",
      "âœ… Validation Loss: 0.000338\n",
      "ðŸ“‰ RMSE: 0.0184 | MAE: 0.0107 | RÂ² Score: 0.9268\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [35/80]\n",
      "âœ… Training Loss: 0.000148\n",
      "âœ… Validation Loss: 0.000312\n",
      "ðŸ“‰ RMSE: 0.0177 | MAE: 0.0105 | RÂ² Score: 0.9323\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [36/80]\n",
      "âœ… Training Loss: 0.000147\n",
      "âœ… Validation Loss: 0.000292\n",
      "ðŸ“‰ RMSE: 0.0171 | MAE: 0.0091 | RÂ² Score: 0.9367\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [37/80]\n",
      "âœ… Training Loss: 0.000146\n",
      "âœ… Validation Loss: 0.000295\n",
      "ðŸ“‰ RMSE: 0.0172 | MAE: 0.0103 | RÂ² Score: 0.9362\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [38/80]\n",
      "âœ… Training Loss: 0.000143\n",
      "âœ… Validation Loss: 0.000286\n",
      "ðŸ“‰ RMSE: 0.0169 | MAE: 0.0093 | RÂ² Score: 0.9382\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [39/80]\n",
      "âœ… Training Loss: 0.000141\n",
      "âœ… Validation Loss: 0.000263\n",
      "ðŸ“‰ RMSE: 0.0162 | MAE: 0.0091 | RÂ² Score: 0.9430\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [40/80]\n",
      "âœ… Training Loss: 0.000145\n",
      "âœ… Validation Loss: 0.000261\n",
      "ðŸ“‰ RMSE: 0.0162 | MAE: 0.0080 | RÂ² Score: 0.9434\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [41/80]\n",
      "âœ… Training Loss: 0.000144\n",
      "âœ… Validation Loss: 0.000282\n",
      "ðŸ“‰ RMSE: 0.0168 | MAE: 0.0082 | RÂ² Score: 0.9390\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [42/80]\n",
      "âœ… Training Loss: 0.000144\n",
      "âœ… Validation Loss: 0.000280\n",
      "ðŸ“‰ RMSE: 0.0167 | MAE: 0.0089 | RÂ² Score: 0.9394\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [43/80]\n",
      "âœ… Training Loss: 0.000138\n",
      "âœ… Validation Loss: 0.000291\n",
      "ðŸ“‰ RMSE: 0.0171 | MAE: 0.0098 | RÂ² Score: 0.9369\n",
      "ðŸ›‘ No improvement. Early stopping counter: 3/10\n",
      "\n",
      "ðŸ“Š Epoch [44/80]\n",
      "âœ… Training Loss: 0.000137\n",
      "âœ… Validation Loss: 0.000275\n",
      "ðŸ“‰ RMSE: 0.0166 | MAE: 0.0090 | RÂ² Score: 0.9405\n",
      "ðŸ›‘ No improvement. Early stopping counter: 4/10\n",
      "\n",
      "ðŸ“Š Epoch [45/80]\n",
      "âœ… Training Loss: 0.000133\n",
      "âœ… Validation Loss: 0.000275\n",
      "ðŸ“‰ RMSE: 0.0166 | MAE: 0.0091 | RÂ² Score: 0.9403\n",
      "ðŸ›‘ No improvement. Early stopping counter: 5/10\n",
      "\n",
      "ðŸ“Š Epoch [46/80]\n",
      "âœ… Training Loss: 0.000127\n",
      "âœ… Validation Loss: 0.000287\n",
      "ðŸ“‰ RMSE: 0.0169 | MAE: 0.0081 | RÂ² Score: 0.9378\n",
      "ðŸ›‘ No improvement. Early stopping counter: 6/10\n",
      "\n",
      "ðŸ“Š Epoch [47/80]\n",
      "âœ… Training Loss: 0.000126\n",
      "âœ… Validation Loss: 0.000321\n",
      "ðŸ“‰ RMSE: 0.0179 | MAE: 0.0095 | RÂ² Score: 0.9304\n",
      "ðŸ›‘ No improvement. Early stopping counter: 7/10\n",
      "\n",
      "ðŸ“Š Epoch [48/80]\n",
      "âœ… Training Loss: 0.000123\n",
      "âœ… Validation Loss: 0.000255\n",
      "ðŸ“‰ RMSE: 0.0160 | MAE: 0.0076 | RÂ² Score: 0.9448\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [49/80]\n",
      "âœ… Training Loss: 0.000121\n",
      "âœ… Validation Loss: 0.000257\n",
      "ðŸ“‰ RMSE: 0.0160 | MAE: 0.0075 | RÂ² Score: 0.9444\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [50/80]\n",
      "âœ… Training Loss: 0.000117\n",
      "âœ… Validation Loss: 0.000251\n",
      "ðŸ“‰ RMSE: 0.0159 | MAE: 0.0080 | RÂ² Score: 0.9456\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [51/80]\n",
      "âœ… Training Loss: 0.000116\n",
      "âœ… Validation Loss: 0.000244\n",
      "ðŸ“‰ RMSE: 0.0156 | MAE: 0.0080 | RÂ² Score: 0.9472\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [52/80]\n",
      "âœ… Training Loss: 0.000117\n",
      "âœ… Validation Loss: 0.000304\n",
      "ðŸ“‰ RMSE: 0.0174 | MAE: 0.0081 | RÂ² Score: 0.9343\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [53/80]\n",
      "âœ… Training Loss: 0.000116\n",
      "âœ… Validation Loss: 0.000293\n",
      "ðŸ“‰ RMSE: 0.0171 | MAE: 0.0078 | RÂ² Score: 0.9365\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [54/80]\n",
      "âœ… Training Loss: 0.000112\n",
      "âœ… Validation Loss: 0.000251\n",
      "ðŸ“‰ RMSE: 0.0158 | MAE: 0.0073 | RÂ² Score: 0.9457\n",
      "ðŸ›‘ No improvement. Early stopping counter: 3/10\n",
      "\n",
      "ðŸ“Š Epoch [55/80]\n",
      "âœ… Training Loss: 0.000111\n",
      "âœ… Validation Loss: 0.000252\n",
      "ðŸ“‰ RMSE: 0.0159 | MAE: 0.0070 | RÂ² Score: 0.9455\n",
      "ðŸ›‘ No improvement. Early stopping counter: 4/10\n",
      "\n",
      "ðŸ“Š Epoch [56/80]\n",
      "âœ… Training Loss: 0.000111\n",
      "âœ… Validation Loss: 0.000272\n",
      "ðŸ“‰ RMSE: 0.0165 | MAE: 0.0076 | RÂ² Score: 0.9411\n",
      "ðŸ›‘ No improvement. Early stopping counter: 5/10\n",
      "\n",
      "ðŸ“Š Epoch [57/80]\n",
      "âœ… Training Loss: 0.000109\n",
      "âœ… Validation Loss: 0.000253\n",
      "ðŸ“‰ RMSE: 0.0159 | MAE: 0.0076 | RÂ² Score: 0.9452\n",
      "ðŸ›‘ No improvement. Early stopping counter: 6/10\n",
      "\n",
      "ðŸ“Š Epoch [58/80]\n",
      "âœ… Training Loss: 0.000107\n",
      "âœ… Validation Loss: 0.000282\n",
      "ðŸ“‰ RMSE: 0.0168 | MAE: 0.0086 | RÂ² Score: 0.9389\n",
      "ðŸ›‘ No improvement. Early stopping counter: 7/10\n",
      "\n",
      "ðŸ“Š Epoch [59/80]\n",
      "âœ… Training Loss: 0.000108\n",
      "âœ… Validation Loss: 0.000257\n",
      "ðŸ“‰ RMSE: 0.0160 | MAE: 0.0068 | RÂ² Score: 0.9444\n",
      "ðŸ›‘ No improvement. Early stopping counter: 8/10\n",
      "\n",
      "ðŸ“Š Epoch [60/80]\n",
      "âœ… Training Loss: 0.000111\n",
      "âœ… Validation Loss: 0.000257\n",
      "ðŸ“‰ RMSE: 0.0160 | MAE: 0.0077 | RÂ² Score: 0.9444\n",
      "ðŸ›‘ No improvement. Early stopping counter: 9/10\n",
      "\n",
      "ðŸ“Š Epoch [61/80]\n",
      "âœ… Training Loss: 0.000106\n",
      "âœ… Validation Loss: 0.000237\n",
      "ðŸ“‰ RMSE: 0.0154 | MAE: 0.0065 | RÂ² Score: 0.9488\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [62/80]\n",
      "âœ… Training Loss: 0.000103\n",
      "âœ… Validation Loss: 0.000301\n",
      "ðŸ“‰ RMSE: 0.0173 | MAE: 0.0069 | RÂ² Score: 0.9349\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [63/80]\n",
      "âœ… Training Loss: 0.000105\n",
      "âœ… Validation Loss: 0.000248\n",
      "ðŸ“‰ RMSE: 0.0158 | MAE: 0.0079 | RÂ² Score: 0.9462\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [64/80]\n",
      "âœ… Training Loss: 0.000100\n",
      "âœ… Validation Loss: 0.000243\n",
      "ðŸ“‰ RMSE: 0.0156 | MAE: 0.0075 | RÂ² Score: 0.9473\n",
      "ðŸ›‘ No improvement. Early stopping counter: 3/10\n",
      "\n",
      "ðŸ“Š Epoch [65/80]\n",
      "âœ… Training Loss: 0.000100\n",
      "âœ… Validation Loss: 0.000285\n",
      "ðŸ“‰ RMSE: 0.0169 | MAE: 0.0077 | RÂ² Score: 0.9383\n",
      "ðŸ›‘ No improvement. Early stopping counter: 4/10\n",
      "\n",
      "ðŸ“Š Epoch [66/80]\n",
      "âœ… Training Loss: 0.000098\n",
      "âœ… Validation Loss: 0.000229\n",
      "ðŸ“‰ RMSE: 0.0151 | MAE: 0.0066 | RÂ² Score: 0.9504\n",
      "ðŸ’¾ Model improved! Saving new best model to best_model.pth\n",
      "\n",
      "ðŸ“Š Epoch [67/80]\n",
      "âœ… Training Loss: 0.000100\n",
      "âœ… Validation Loss: 0.000319\n",
      "ðŸ“‰ RMSE: 0.0179 | MAE: 0.0073 | RÂ² Score: 0.9308\n",
      "ðŸ›‘ No improvement. Early stopping counter: 1/10\n",
      "\n",
      "ðŸ“Š Epoch [68/80]\n",
      "âœ… Training Loss: 0.000100\n",
      "âœ… Validation Loss: 0.000267\n",
      "ðŸ“‰ RMSE: 0.0163 | MAE: 0.0073 | RÂ² Score: 0.9422\n",
      "ðŸ›‘ No improvement. Early stopping counter: 2/10\n",
      "\n",
      "ðŸ“Š Epoch [69/80]\n",
      "âœ… Training Loss: 0.000096\n",
      "âœ… Validation Loss: 0.000283\n",
      "ðŸ“‰ RMSE: 0.0168 | MAE: 0.0074 | RÂ² Score: 0.9388\n",
      "ðŸ›‘ No improvement. Early stopping counter: 3/10\n",
      "\n",
      "ðŸ“Š Epoch [70/80]\n",
      "âœ… Training Loss: 0.000094\n",
      "âœ… Validation Loss: 0.000276\n",
      "ðŸ“‰ RMSE: 0.0166 | MAE: 0.0073 | RÂ² Score: 0.9402\n",
      "ðŸ›‘ No improvement. Early stopping counter: 4/10\n",
      "\n",
      "ðŸ“Š Epoch [71/80]\n",
      "âœ… Training Loss: 0.000094\n",
      "âœ… Validation Loss: 0.000258\n",
      "ðŸ“‰ RMSE: 0.0161 | MAE: 0.0072 | RÂ² Score: 0.9442\n",
      "ðŸ›‘ No improvement. Early stopping counter: 5/10\n",
      "\n",
      "ðŸ“Š Epoch [72/80]\n",
      "âœ… Training Loss: 0.000095\n",
      "âœ… Validation Loss: 0.000305\n",
      "ðŸ“‰ RMSE: 0.0175 | MAE: 0.0064 | RÂ² Score: 0.9340\n",
      "ðŸ›‘ No improvement. Early stopping counter: 6/10\n",
      "\n",
      "ðŸ“Š Epoch [73/80]\n",
      "âœ… Training Loss: 0.000094\n",
      "âœ… Validation Loss: 0.000276\n",
      "ðŸ“‰ RMSE: 0.0166 | MAE: 0.0078 | RÂ² Score: 0.9403\n",
      "ðŸ›‘ No improvement. Early stopping counter: 7/10\n",
      "\n",
      "ðŸ“Š Epoch [74/80]\n",
      "âœ… Training Loss: 0.000092\n",
      "âœ… Validation Loss: 0.000336\n",
      "ðŸ“‰ RMSE: 0.0183 | MAE: 0.0072 | RÂ² Score: 0.9272\n",
      "ðŸ›‘ No improvement. Early stopping counter: 8/10\n",
      "\n",
      "ðŸ“Š Epoch [75/80]\n",
      "âœ… Training Loss: 0.000094\n",
      "âœ… Validation Loss: 0.000350\n",
      "ðŸ“‰ RMSE: 0.0187 | MAE: 0.0077 | RÂ² Score: 0.9242\n",
      "ðŸ›‘ No improvement. Early stopping counter: 9/10\n",
      "\n",
      "ðŸ“Š Epoch [76/80]\n",
      "âœ… Training Loss: 0.000091\n",
      "âœ… Validation Loss: 0.000274\n",
      "ðŸ“‰ RMSE: 0.0166 | MAE: 0.0075 | RÂ² Score: 0.9407\n",
      "ðŸ›‘ No improvement. Early stopping counter: 10/10\n",
      "\n",
      "ðŸš€ Early stopping triggered! Loading best model.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import os\n",
    "\n",
    "# move data to GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "X_valid, y_valid = X_valid.to(device), y_valid.to(device)\n",
    "\n",
    "#set up model using parameters from config\n",
    "model = LSTM_fr_model(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "\n",
    "# loss & optim \n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# scheduler \n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=10, factor=0.3, threshold=5e-4, min_lr=5e-7)\n",
    "\n",
    "# early stopping\n",
    "early_stopping_patience = 10  # Stop training if no improvement for 10 epochs\n",
    "best_valid_loss = float('inf')\n",
    "early_stopping_counter = 0\n",
    "best_model_path = \"best_model.pth\"  # Path to save best model\n",
    "\n",
    "# training loop\n",
    "for epoch in range(num_epochs):  # loop over the epochs (outer)\n",
    "    model.train()  # set model to training mode\n",
    "    epoch_losses = 0  # track total loss per epoch\n",
    "\n",
    "    for i in range(0, len(X_train), batch_size):  # inner loop over mini-batches\n",
    "        x_batch = X_train[i:i + batch_size]\n",
    "        y_batch = y_train[i:i + batch_size]\n",
    "\n",
    "        # Ensure correct shape for LSTM\n",
    "        x_batch = x_batch.view(x_batch.shape[0], sequence_length, input_size)\n",
    "\n",
    "        # Move batch to GPU\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # zero the gradients before backpropagation\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(x_batch)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(outputs, y_batch.view(-1, 1))\n",
    "\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # running total of loss for epoch\n",
    "        epoch_losses += loss.item()\n",
    "\n",
    "    # Compute average loss for the epoch\n",
    "    train_loss = epoch_losses / (len(X_train) // batch_size)\n",
    "\n",
    "    # Validation loss  \n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        X_valid = X_valid.view(X_valid.shape[0], sequence_length, input_size)  # Ensure correct shape\n",
    "        X_valid = X_valid.to(device)\n",
    "        valid_predictions = model(X_valid).cpu().numpy().flatten()\n",
    "        valid_actuals = y_valid.cpu().numpy().flatten()\n",
    "    \n",
    "    valid_loss = mean_squared_error(valid_actuals, valid_predictions)\n",
    "\n",
    "    #per-epoch log\n",
    "    print(f\"\\Epoch [{epoch+1}/{num_epochs}]\")\n",
    "    print(f\"Training Loss: {train_loss:.6f}\")\n",
    "    print(f\"Validation Loss: {valid_loss:.6f}\")\n",
    "\n",
    "    # RMSE, MAE, coefficient of determination\n",
    "    rmse = np.sqrt(valid_loss)\n",
    "    mae = mean_absolute_error(valid_actuals, valid_predictions)\n",
    "    r2 = r2_score(valid_actuals, valid_predictions)\n",
    "\n",
    "    print(f\"RMSE: {rmse:.4f} | MAE: {mae:.4f} | RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "    # check for early stop\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        early_stopping_counter = 0  # Reset counter\n",
    "        torch.save(model.state_dict(), best_model_path)  # Save best model\n",
    "        print(f\"Model improved. Saving new best model to {best_model_path}\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        print(f\"No improvement. Early stopping counter: {early_stopping_counter}/{early_stopping_patience}\")\n",
    "\n",
    "    if early_stopping_counter >= early_stopping_patience:\n",
    "        print(\"\\nEarly stop, loading best model.\")\n",
    "        model.load_state_dict(torch.load(best_model_path, weights_only=True))  # FIXED\n",
    "        break\n",
    "\n",
    "    # Update learning rate scheduler\n",
    "    scheduler.step(valid_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T06:42:34.895726Z",
     "iopub.status.busy": "2025-02-10T06:42:34.895282Z",
     "iopub.status.idle": "2025-02-10T06:42:36.754895Z",
     "shell.execute_reply": "2025-02-10T06:42:36.754107Z",
     "shell.execute_reply.started": "2025-02-10T06:42:34.895694Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Metrics (Best Model Loaded):\n",
      "MSE (Mean Squared Error): 2.4598\n",
      "RMSE (Root Mean Squared Error): 1.5684\n",
      "MAE (Mean Absolute Error): 0.6112\n",
      "MAPE (Mean Absolute Percentage Error): 6.23%\n",
      "RÂ² Score: 0.9439\n",
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-07 17:18:35.173 python[99132:4224548] +[IMKClient subclass]: chose IMKClient_Modern\n",
      "2025-03-07 17:18:35.173 python[99132:4224548] +[IMKInputSession subclass]: chose IMKInputSession_Modern\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "\n",
    "# Load the best model \n",
    "best_model_path = \"best_model.pth\"  # Ensure this path matches the saved model in training\n",
    "model = LSTM_fr_model(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "model.load_state_dict(torch.load(best_model_path,map_location=torch.device('cpu'), weights_only=False)) # move to CPu\n",
    "model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "# Run predictions on the test set\n",
    "with torch.no_grad():\n",
    "    X_test = X_test.view(X_test.shape[0], sequence_length, input_size)  # Ensure correct shape\n",
    "    X_test = X_test.to(device)  # Move to GPU if available\n",
    "    predictions = model(X_test).cpu().numpy().flatten() * (test_max - test_min) + test_min # Convert to 1D NumPy array\n",
    "    actuals = y_test.cpu().numpy().flatten() * (test_max - test_min) + test_min  # Convert to 1D NumPy array\n",
    "\n",
    "# Run predictions on the validation set\n",
    "with torch.no_grad():\n",
    "    X_valid = X_valid.view(X_valid.shape[0], sequence_length, input_size)  # Ensure correct shape\n",
    "    X_valid = X_valid.to(device)  # Move to GPU if available\n",
    "    valid_predictions = model(X_valid).cpu().numpy().flatten() * (valid_max - valid_min) + valid_min # Convert to 1D NumPy array\n",
    "    valid_actuals = y_valid.cpu().numpy().flatten() * (valid_max - valid_min) + valid_min  # Convert to 1D NumPy array\n",
    "\n",
    "#denormalize the training set\n",
    "y_train_denormalized = y_train.cpu().numpy().flatten() * (train_max - train_min) + train_min\n",
    "\n",
    "# Handle potential division by zero in MAPE calculation\n",
    "nonzero_mask = actuals != 0\n",
    "if np.any(nonzero_mask):\n",
    "    mape = np.mean(np.abs((actuals[nonzero_mask] - predictions[nonzero_mask]) / actuals[nonzero_mask])) * 100\n",
    "else:\n",
    "    mape = np.nan  # If all actual values are zero, MAPE is not defined\n",
    "\n",
    "# Compute Metrics\n",
    "mse = mean_squared_error(actuals, predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(actuals, predictions)\n",
    "r2 = r2_score(actuals, predictions)\n",
    "\n",
    "#Print Evaluation Metrics\n",
    "print(\"\\nModel Evaluation Metrics (Best Model Loaded):\")\n",
    "print(f\"MSE (Mean Squared Error): {mse:.4f}\")\n",
    "print(f\"RMSE (Root Mean Squared Error): {rmse:.4f}\")\n",
    "print(f\"MAE (Mean Absolute Error): {mae:.4f}\")\n",
    "print(f\"MAPE (Mean Absolute Percentage Error): {mape:.2f}%\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "#Create time indices\n",
    "train_size = len(y_train)\n",
    "valid_size = len(y_valid)\n",
    "test_size = len(y_test)\n",
    "\n",
    "train_index = np.arange(0, train_size)\n",
    "valid_index = np.arange(train_size, train_size + valid_size)\n",
    "test_index = np.arange(train_size + valid_size, train_size + valid_size + test_size)\n",
    "\n",
    "%pylab qt\n",
    "plt.figure(figsize=(12, 6))\n",
    "# Define the start and end dates for the x-axis\n",
    "years = np.linspace(1964, 2022, num=6, dtype=int)  # Generate 6 year ticks\n",
    "x_positions = np.linspace(0, 595083, num=6)  # Match them with x-axis positions\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.plot(train_index, y_train_denormalized, label=\"Training Data\", color=\"blue\", alpha=1, linewidth=1.2)\n",
    "ax.plot(valid_index, valid_actuals, label=\"Actual Validation Data\", color=\"purple\", linestyle=\"solid\", alpha=0.9, linewidth=1.2)\n",
    "ax.plot(test_index, actuals, label=\"Actual Test Data\", color=\"green\", linestyle=\"solid\", alpha=0.9, linewidth=1.2)\n",
    "ax.plot(test_index, predictions, label=\"Predicted Test Data\", color=\"red\", linestyle=\"dashed\", alpha=0.7, linewidth=1.2)\n",
    "\n",
    "# Set x-axis labels\n",
    "ax.set_xticks(x_positions)\n",
    "ax.set_xticklabels(years)\n",
    "\n",
    "# Labels and title\n",
    "ax.set_xlabel(\"Time (years)\")\n",
    "ax.set_ylabel(\"Flow Rate\")\n",
    "ax.set_title(\"Time Series of Test Data with Model Predictions\")\n",
    "\n",
    "# Legend and grid\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-10T06:40:29.532078Z",
     "iopub.status.busy": "2025-02-10T06:40:29.531859Z",
     "iopub.status.idle": "2025-02-10T06:40:29.537428Z",
     "shell.execute_reply": "2025-02-10T06:40:29.536543Z",
     "shell.execute_reply.started": "2025-02-10T06:40:29.532058Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='best_model.pth' target='_blank'>best_model.pth</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/best_model.pth"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "\n",
    "# Define the path to the saved model\n",
    "model_path = \"best_model.pth\"\n",
    "\n",
    "# Create a download link\n",
    "FileLink(model_path)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 6634418,
     "sourceId": 10704990,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
